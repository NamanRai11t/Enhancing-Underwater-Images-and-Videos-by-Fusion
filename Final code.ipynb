{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import exposure as ex\n",
    "import imageio\n",
    "import math\n",
    "import threading as th\n",
    "import time\n",
    "import queue\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GaussianPyramid(img,level):\n",
    "    g=img.copy()\n",
    "    gp=[g]\n",
    "    for i in range(level):\n",
    "        g=cv2.pyrDown(g)\n",
    "        gp.append(g)\n",
    "    return gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LaplacianPyramid(img,level):\n",
    "    l=img.copy()\n",
    "    gp=GaussianPyramid(img,level)\n",
    "    lp=[gp[level]]\n",
    "    for i in range(level,0,-1):\n",
    "        size=(gp[i-1].shape[1],gp[i-1].shape[0])\n",
    "        ge=cv2.pyrUp(gp[i],dstsize=size)\n",
    "        l=cv2.subtract(gp[i-1],ge)\n",
    "        lp.append(l)\n",
    "    lp.reverse()\n",
    "    return lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def PyramidReconstruct(lapl_pyr):\n",
    "  output = None\n",
    "  output = np.zeros((lapl_pyr[0].shape[0],lapl_pyr[0].shape[1]), dtype=np.float64)\n",
    "  for i in range(len(lapl_pyr)-1,0,-1):\n",
    "    lap = cv2.pyrUp(lapl_pyr[i])\n",
    "    lapb = lapl_pyr[i-1]\n",
    "    if lap.shape[0] > lapb.shape[0]:\n",
    "      lap = np.delete(lap,(-1),axis=0)\n",
    "    if lap.shape[1] > lapb.shape[1]:\n",
    "      lap = np.delete(lap,(-1),axis=1)\n",
    "    tmp = lap + lapb\n",
    "    lapl_pyr.pop()\n",
    "    lapl_pyr.pop()\n",
    "    lapl_pyr.append(tmp)\n",
    "    output = tmp\n",
    "  return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Exposedness(img):\n",
    "    sigma=0.25\n",
    "    average=0.5\n",
    "    row=img.shape[0]\n",
    "    col=img.shape[1]\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    cv2.normalize(gray, dst=gray, alpha=0.0, beta=1.0, norm_type=cv2.NORM_MINMAX)\n",
    "    res=np.zeros((row,col), np.float32)\n",
    "    for i in range(row):\n",
    "        for j in range(col):\n",
    "            res[i,j]=math.exp(-1.0*math.pow(gray[i,j]-average,2.0)/(2*math.pow(sigma,2.0)))\n",
    "    res=(res*255)\n",
    "    res = cv2.convertScaleAbs(res)\n",
    "    return res       \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serial Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Fusion(w1,w2,img1,img2):\n",
    "    a = time.time()\n",
    "    \n",
    "    level=5\n",
    "    weight1=GaussianPyramid(w1,level)\n",
    "    weight2=GaussianPyramid(w2,level)\n",
    "    b1,g1,r1=cv2.split(img1)\n",
    "    b_pyr1=LaplacianPyramid(b1,level)\n",
    "    g_pyr1=LaplacianPyramid(g1,level)\n",
    "    r_pyr1=LaplacianPyramid(r1,level)\n",
    "    b2,g2,r2=cv2.split(img2)\n",
    "    b_pyr2=LaplacianPyramid(b2,level)\n",
    "    g_pyr2=LaplacianPyramid(g2,level)\n",
    "    r_pyr2=LaplacianPyramid(r2,level)\n",
    "    b_pyr=[]\n",
    "    g_pyr=[]\n",
    "    r_pyr=[]\n",
    "    for i in range(level):\n",
    "        b_pyr.append(cv2.add(cv2.multiply(weight1[i],b_pyr1[i]),cv2.multiply(weight2[i],b_pyr2[i])))\n",
    "        g_pyr.append(cv2.add(cv2.multiply(weight1[i],g_pyr1[i]),cv2.multiply(weight2[i],g_pyr2[i])))\n",
    "        r_pyr.append(cv2.add(cv2.multiply(weight1[i],r_pyr1[i]),cv2.multiply(weight2[i],r_pyr2[i])))\n",
    "    b_channel=PyramidReconstruct(b_pyr)\n",
    "    g_channel=PyramidReconstruct(g_pyr)\n",
    "    r_channel=PyramidReconstruct(r_pyr)\n",
    "    out_img=cv2.merge((b_channel,g_channel,r_channel))\n",
    "    \n",
    "    print(\"Normal done in \", time.time()-a)\n",
    "    return out_img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ApplyGuass_ll(w1, w2, level):\n",
    "    que = queue.Queue()\n",
    "    #weight1=GaussianPyramid(w1,level)\n",
    "    #weight2=GaussianPyramid(w2,level)\n",
    "    t1 = th.Thread(target=lambda q, arg1,arg2: q.put(GaussianPyramid(arg1,arg2)), args=(que, w1, level))\n",
    "    t1.start()\n",
    "    t1.join()\n",
    "    t2 = th.Thread(target=lambda q, arg1,arg2: q.put(GaussianPyramid(arg1,arg2)), args=(que, w2, level))\n",
    "    t2.start()\n",
    "    t2.join()\n",
    "    weight1 = que.get()\n",
    "    weight2 = que.get()\n",
    "    arr = [weight1, weight2]\n",
    "    return arr\n",
    "\n",
    "def ApllyLaplac_ll(b1, g1, r1, b2, g2, r2, level):\n",
    "    que = queue.Queue()\n",
    "    #b_pyr1=LaplacianPyramid(b1,level)\n",
    "    #g_pyr1=LaplacianPyramid(g1,level)\n",
    "    #r_pyr1=LaplacianPyramid(r1,level)\n",
    "    t3 = th.Thread(target=lambda q, arg1,arg2: q.put(LaplacianPyramid(arg1,arg2)), args=(que, b1, level))\n",
    "    t3.start()\n",
    "    t3.join()\n",
    "    t4 = th.Thread(target=lambda q, arg1,arg2: q.put(LaplacianPyramid(arg1,arg2)), args=(que, g1, level))\n",
    "    t4.start()\n",
    "    t4.join()\n",
    "    t5 = th.Thread(target=lambda q, arg1,arg2: q.put(LaplacianPyramid(arg1,arg2)), args=(que, r1, level))\n",
    "    t5.start()\n",
    "    t5.join()\n",
    "    #b_pyr2=LaplacianPyramid(b2,level)\n",
    "    #g_pyr2=LaplacianPyramid(g2,level)\n",
    "    #r_pyr2=LaplacianPyramid(r2,level)\n",
    "    t6 = th.Thread(target=lambda q, arg1,arg2: q.put(LaplacianPyramid(arg1,arg2)), args=(que, b2, level))\n",
    "    t6.start()\n",
    "    t6.join()\n",
    "    t7 = th.Thread(target=lambda q, arg1,arg2: q.put(LaplacianPyramid(arg1,arg2)), args=(que, g2, level))\n",
    "    t7.start()\n",
    "    t7.join()\n",
    "    t8 = th.Thread(target=lambda q, arg1,arg2: q.put(LaplacianPyramid(arg1,arg2)), args=(que, r2, level))\n",
    "    t8.start()\n",
    "    #join all\n",
    "    t8.join()\n",
    "    #getting result\n",
    "    arr = []\n",
    "    for i in range(6):\n",
    "        arr.append(que.get())\n",
    "    return arr\n",
    "\n",
    "def ApplyFusion_ll(b_pyr, g_pyr, r_pyr):\n",
    "    que = queue.Queue()\n",
    "    #b_channel=PyramidReconstruct(b_pyr)\n",
    "    #g_channel=PyramidReconstruct(g_pyr)\n",
    "    #r_channel=PyramidReconstruct(r_pyr)\n",
    "    x1 = th.Thread(target=lambda q, arg1: q.put(PyramidReconstruct(arg1)), args=(que, b_pyr))\n",
    "    x1.start()\n",
    "    x1.join()\n",
    "    x2 = th.Thread(target=lambda q, arg1: q.put(PyramidReconstruct(arg1)), args=(que, g_pyr))\n",
    "    x2.start()\n",
    "    x2.join()\n",
    "    x3 = th.Thread(target=lambda q, arg1: q.put(PyramidReconstruct(arg1)), args=(que, r_pyr))\n",
    "    x3.start()\n",
    "    x3.join()\n",
    "    #getting result\n",
    "    arr = []\n",
    "    for i in range(3):\n",
    "        arr.append(que.get())\n",
    "    return arr\n",
    "    \n",
    "\n",
    "def Fusion_Pll(w1,w2,img1,img2):\n",
    "    a = time.time()\n",
    "    level=5\n",
    "    #GuassianPyramid\n",
    "    weight = ApplyGuass_ll(w1, w2, level)\n",
    "    weight1 = weight[0]\n",
    "    weight2 = weight[1]\n",
    "    b1,g1,r1=cv2.split(img1)\n",
    "    b2,g2,r2=cv2.split(img2)\n",
    "    #LaplacianPyramid\n",
    "    pyr = ApllyLaplac_ll(b1, g1, r1, b2, g2, r2, level)\n",
    "    b_pyr1 = pyr[0]\n",
    "    g_pyr1 = pyr[1]\n",
    "    r_pyr1 = pyr[2]\n",
    "    b_pyr2 = pyr[3]\n",
    "    g_pyr2 = pyr[4]\n",
    "    r_pyr2 = pyr[5]\n",
    "    #prefusioncode\n",
    "    b_pyr=[]\n",
    "    g_pyr=[]\n",
    "    r_pyr=[]\n",
    "    for i in range(level):\n",
    "        b_pyr.append(cv2.add(cv2.multiply(weight1[i],b_pyr1[i]),cv2.multiply(weight2[i],b_pyr2[i])))\n",
    "        g_pyr.append(cv2.add(cv2.multiply(weight1[i],g_pyr1[i]),cv2.multiply(weight2[i],g_pyr2[i])))\n",
    "        r_pyr.append(cv2.add(cv2.multiply(weight1[i],r_pyr1[i]),cv2.multiply(weight2[i],r_pyr2[i])))\n",
    "        \n",
    "    channel = ApplyFusion_ll(b_pyr, g_pyr, r_pyr)\n",
    "    b_channel = channel[0]\n",
    "    g_channel = channel[1]\n",
    "    r_channel = channel[2]\n",
    "    \n",
    "    out_img=cv2.merge((b_channel,g_channel,r_channel))\n",
    "    print(\"Parallel done in \", time.time()-a)\n",
    "    return out_img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# White Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def white_balance(nimg):\n",
    "    if nimg.dtype==np.uint8:\n",
    "        brightest=float(2**8)\n",
    "    elif nimg.dtype==np.uinAt16:\n",
    "        brightest=float(2**16)\n",
    "    elif nimg.dtype==np.uint32:\n",
    "        brightest=float(2**32)\n",
    "    else:\n",
    "        brightest==float(2**8)\n",
    "    nimg = nimg.transpose(2, 0, 1)\n",
    "    nimg = nimg.astype(np.int32)\n",
    "    nimg[0] = np.minimum(nimg[0] * (brightest/float(nimg[0].max())),255)\n",
    "    nimg[1] = np.minimum(nimg[1] * (brightest/float(nimg[1].max())),255)\n",
    "    nimg[2] = np.minimum(nimg[2] * (brightest/float(nimg[2].max())),255)\n",
    "    return nimg.transpose(1, 2, 0).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# White Balance Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculatePx(pmg, brightest, i):\n",
    "    pmg[i] = np.minimum(pmg[i]*(brightest/float(pmg[i].max())), 255)\n",
    "\n",
    "def white_balance_ll(nimg):\n",
    "    if nimg.dtype==np.uint8:\n",
    "        brightest=float(2**8)\n",
    "    elif nimg.dtype==np.uinAt16:\n",
    "        brightest=float(2**16)\n",
    "    elif nimg.dtype==np.uint32:\n",
    "        brightest=float(2**32)\n",
    "    else:\n",
    "        brightest==float(2**8)\n",
    "    nimg = nimg.transpose(2, 0, 1)\n",
    "    nimg = nimg.astype(np.int32)\n",
    "    \n",
    "    x1 = th.Thread(target=calculatePx, args=(nimg, brightest, 0,))\n",
    "    x2 = th.Thread(target=calculatePx, args=(nimg, brightest, 1,))\n",
    "    x3 = th.Thread(target=calculatePx, args=(nimg, brightest, 2,))\n",
    "    x1.start()\n",
    "    x2.start()\n",
    "    x3.start()\n",
    "    x1.join()\n",
    "    x2.join()\n",
    "    x3.join()\n",
    "    \n",
    "    return nimg.transpose(1, 2, 0).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Color Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_balance(img,percent):\n",
    "    if percent<=0:\n",
    "        percent=5 # taken as an average of (1-10).\n",
    "        \n",
    "    rows=img.shape[0]\n",
    "    cols=img.shape[1]\n",
    "    no_of_chanl=img.shape[2] # knowing the no. of channels in the present image\n",
    "    \n",
    "    halfpercent = percent/200.0 # halving the given percentage based on the given research paper\n",
    "    \n",
    "    channels=[] # list for storing all the present channels of the image separately.\n",
    "    \n",
    "    if no_of_chanl==3:\n",
    "        for i in range(3):\n",
    "            channels.append(img[:,:,i:i+1]) # add all the present channels of the image to this list separately\n",
    "    else:\n",
    "        channels.append(img)\n",
    "        \n",
    "    results=[]\n",
    "    \n",
    "    for i in range(no_of_chanl):\n",
    "        #print(channels[i].shape)\n",
    "        plane=channels[i].reshape(1,rows*cols,1)\n",
    "        plane.sort()\n",
    "        lower_value= plane[0][int(plane.shape[1]*halfpercent)][0]\n",
    "        top_value = plane[0][int(plane.shape[1]*(1-halfpercent))][0]\n",
    "        \n",
    "        channel = channels[i]\n",
    "        \n",
    "        for p in range(rows):\n",
    "            for q in range(cols):\n",
    "                if channel[p][q][0] < lower_value :\n",
    "                    channel[p][q][0]=lower_value\n",
    "                if channel[p][q][0] < top_value :\n",
    "                    channel[p][q][0]=top_value\n",
    "        \n",
    "        channel=cv2.normalize(channel,None,0.0,255.0/2,cv2.NORM_MINMAX)\n",
    "        # convert the image in desired format-converted\n",
    "        \n",
    "        results.append(channel)\n",
    "        \n",
    "    output_image = np.zeros((rows,cols,3))\n",
    "    #for x in results:\n",
    "        #cv2.imshow('image',x)\n",
    "        #cv2.waitKey(0)\n",
    "        #cv2.destroyAllWindows()\n",
    "    output_image=cv2.merge(results)\n",
    "    return output_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contrast Enhance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def he(img):\n",
    "    if(len(img.shape)==2):      #gray\n",
    "        outImg = ex.equalize_hist(img[:,:])*255 \n",
    "    elif(len(img.shape)==3):    #RGB\n",
    "        outImg = np.zeros((img.shape[0],img.shape[1],3))\n",
    "        for channel in range(img.shape[2]):\n",
    "            outImg[:, :, channel] = ex.equalize_hist(img[:, :, channel])*255\n",
    "\n",
    "    outImg[outImg>255] = 255\n",
    "    outImg[outImg<0] = 0\n",
    "    return outImg.astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallel contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pcont(outImg , channel, img):\n",
    "    outImg[:, :, channel] = ex.equalize_hist(img[:, :, channel])*255\n",
    "\n",
    "def he_ll(img):\n",
    "    if(len(img.shape)==2):      #gray\n",
    "        outImg = ex.equalize_hist(img[:,:])*255 \n",
    "    elif(len(img.shape)==3):    #RGB\n",
    "        outImg = np.zeros((img.shape[0],img.shape[1],3))\n",
    "        #for channel in range(img.shape[2]):\n",
    "         #   sid = th.Thread(target=lambda q, arg1, arg2, arg3: q.put(pcont(arg1, arg2, arg3)), args=(que, outImg, channel, img))\n",
    "          #  sid.start()\n",
    "           # sid.join()\n",
    "        s1 = th.Thread(target=pcont, args=(outImg, 0, img,))\n",
    "        s1.start()   \n",
    "        s2 = th.Thread(target=pcont, args=(outImg, 1, img,))\n",
    "        s2.start()\n",
    "        pcont(outImg , 2, img)\n",
    "        s2.join() \n",
    "        s1.join()    \n",
    "        \n",
    "\n",
    "    outImg[outImg>255] = 255\n",
    "    outImg[outImg<0] = 0\n",
    "    return outImg.astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken  0.05283641815185547\n"
     ]
    }
   ],
   "source": [
    "amg = cv2.imread(\"01.jpg\")\n",
    "a = time.time()\n",
    "conimg = he_ll(amg)\n",
    "print(\"Time taken \", time.time()-a)\n",
    "\n",
    "cv2.imshow(\"\",conimg)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serial White_Color Balance and Contrast_enhance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken  1.6392707824707031\n"
     ]
    }
   ],
   "source": [
    "a = time.time()\n",
    "amg = cv2.imread(\"01.jpg\")\n",
    "final_image = white_balance(amg)\n",
    "percent=100.0\n",
    "i4 = color_balance(final_image,percent)\n",
    "\n",
    "\n",
    "img_name = sys.argv[1]\n",
    "i5 = he(amg)\n",
    "print(\"Time taken \", time.time()-a)\n",
    "\n",
    "cv2.imshow(\"\",i4)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "cv2.imshow(\"\",i5)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel White_Color Balance and Contrast_enhance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reqFun(img):\n",
    "    fmg = white_balance_ll(img)\n",
    "    percent = 100.0\n",
    "    i4 = color_balance(final_image,percent)\n",
    "    return i4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken  1.3386080265045166\n"
     ]
    }
   ],
   "source": [
    "a = time.time()\n",
    "\n",
    "amg = cv2.imread(\"01.jpg\")\n",
    "que = queue.Queue()\n",
    "th1 = th.Thread(target=lambda q, arg1: q.put(reqFun(arg1)), args=(que, amg))\n",
    "th1.start()\n",
    "\n",
    "hemg = he(amg)\n",
    "th1.join()\n",
    "wmg = que.get()\n",
    "print(\"Time taken \", time.time()-a)\n",
    "\n",
    "\n",
    "cv2.imshow(\"\",wmg)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "cv2.imshow(\"\",hemg)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal done in  0.07280707359313965\n"
     ]
    }
   ],
   "source": [
    "img4 = i4 #cv2.resize(i4,(512,512),interpolation=cv2.INTER_AREA)\n",
    "gray = cv2.cvtColor(img4, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cv2.imshow(\"\",Fusion(gray,gray,img4,final_image))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parallel done in  0.12267065048217773\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cv2.imshow(\"\",Fusion_Pll(gray,gray,img4,final_image))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
